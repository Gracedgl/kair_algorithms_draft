# ! usr/bin/env python

import time
import numpy as np
import rospy

import gym
from gym import spaces
from gym.utils import seeding

from open_manipulator_robot_env import OpenManipulatorRobotEnv

# Global variables
ACTION_DIM = 3  # Cartesian
OBS_DIM = (100, 100, 3)  # POMDP
STATE_DIM = 24  # MDP


class OpenManipulatorBase(OpenManipulatorRobotEnv, gym.Env):
    def __init__(self, max_steps=700, isdagger=False, isPOMDP=False,
                 isreal=False,
                 train_indicator=0):

        self.action_space = spaces.Box(-1., 1., shape=(ACTION_DIM,), dtype='float32')
        self.observation_space = spaces.Dict(dict(
                observation=spaces.Box(-np.inf, np.inf, shape=obs['observation'].shape,
                                       dtype='float32'),
        ))

        self.train_indicator = train_indicator
        self.isdagger = isdagger
        self.isPOMDP = isPOMDP
        self.isreal = isreal
        self.max_steps = max_steps
        self.done = False
        self.reward = 0
        self.reward_rescale = 1.0

    def seed(self, seed=None):
        self.np_random, seed = seeding.np_random(seed)
        return [seed]

    def step(self, action):
        """Function executed each time step.
        Here we get the action execute it in a time step and retrieve the
        observations generated by that action.
        :param action:
        :return: obs, reward, done
        """
        if action is None:
            action = np.array([1, 1, 1, 1, 1, 1])
        self.prev_tic = self.tic
        self.tic = time.time()
        self.elapsed = time.time() - self.prev_tic
        self.done = False
        if step == self.max_steps:
            self.done = True
        act = action.flatten().tolist()
        self.set_joints_position(act)
        curDist = self._get_dist()
        if not self.isreal:
            self.reward = self._compute_reward()
            if self._check_for_termination():
                print('======================================================')
                print('Terminates current Episode : OUT OF BOUNDARY')
                print('======================================================')
            elif self._check_for_success():
                print('======================================================')
                print('Succeeded current Episode')
                print('======================================================')
        _joint_pos, _joint_vels, _joint_effos = self.get_joints_states()
        # obj_pos = self._get_target_obj_obs() # TODO: implement this
        #  function call.

        if np.mod(step, 10) == 0:
            if not self.isreal:
                print("DISTANCE : ", curDist)
            print("PER STEP ELAPSED : ", self.elapsed)
            print("SPARSE REWARD : ", self.reward_rescale * self.reward)
            print("Current EE pos: ", self.gripper_position)
            print("Actions: ", act)

        obs = np.array([_joint_pos, _joint_vels, _joint_effos])

        return obs, self.reward_rescale * self.reward, self.done

    def reset(self):
        """Attempt to reset the simulator. Since we randomize initial
        conditions, it
        is possible to get into a state with numerical issues (e.g. due to
        penetration or
        Gimbel lock) or we may not achieve an initial condition (e.g. an
        object is within the hand).
        In this case, we just keep randomizing until we eventually achieve
        a valid initial
        configuration."""
        # did_reset_sim = False
        self._reset_gazebo_world()
        _joint_pos, _joint_vels, _joint_effos = self.get_joints_states()
        obs = np.array([_joint_pos, _joint_vels, _joint_effos])

        return obs

    def close(self):
        rospy.signal_shutdown("done")
